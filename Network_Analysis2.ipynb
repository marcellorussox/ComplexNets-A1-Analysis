{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Table of Contents\n",
    "0. Initial Setup\n",
    "1. Part 1\n",
    "   - 1.1 Analysis of net1\n",
    "   - 1.2 Analysis of net2\n",
    "   - 1.3 Analysis of net3\n",
    "   - 1.4 Analysis of net4\n",
    "2. Part 2\n",
    "   - 2.1 Network Visualization\n",
    "   - 2.2 Observations and Hypothesis\n",
    "   - 2.3 Algorithm Construction for the Model\n",
    "   - 2.4 Algorithm proposal testing\n",
    "3. Conclusion\n",
    "\n",
    "\n"
   ],
   "id": "b778995ce4ee3bc6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 0. Initial setup"
   ],
   "id": "98393eaa010a212b"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-23T20:44:41.001204Z",
     "start_time": "2025-03-23T20:44:40.995800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "report_folder = \"report\"\n",
    "import math\n",
    "if not os.path.exists(report_folder):\n",
    "    os.makedirs(report_folder)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `load_network` function reads a network from a Pajek file, converts it into a simple undirected graph, and relabels the nodes with integer values.",
   "id": "40a116c90511ba1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:10.958620Z",
     "start_time": "2025-03-23T20:43:10.956194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_network(name):\n",
    "    \"\"\"\n",
    "    Load and preprocess a network from a Pajek file.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): The name of the Pajek file (without extension).\n",
    "\n",
    "    Returns:\n",
    "        networkx.Graph: A simple undirected graph with integer-labeled nodes.\n",
    "    \"\"\"\n",
    "    G = nx.read_pajek(f'data/{name}.net')\n",
    "\n",
    "    G = nx.Graph(G)\n",
    "\n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "    return G\n"
   ],
   "id": "f4553a7998e13ff4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `calculate_network_descriptors` function computes key structural and macroscopic properties of the network.\n",
   "id": "d833a055b7ad8666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:10.968117Z",
     "start_time": "2025-03-23T20:43:10.963120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_network_descriptors(G):\n",
    "    \"\"\"\n",
    "    Compute key structural and macroscopic descriptors for the given network.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): The input graph.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the following metrics:\n",
    "            - 'nodes': Number of nodes in the network.\n",
    "            - 'edges': Number of edges in the network.\n",
    "            - 'self_loops': Number of self-loops.\n",
    "            - 'multi_edges': Number of multi-edges.\n",
    "            - 'degree_min': Minimum node degree.\n",
    "            - 'degree_max': Maximum node degree.\n",
    "            - 'degree_avg': Average node degree.\n",
    "            - 'clustering': Average clustering coefficient.\n",
    "            - 'assortativity': Degree assortativity coefficient.\n",
    "            - 'avg_path_length': Average shortest path length (largest connected component).\n",
    "            - 'diameter': Diameter of the largest connected component.\n",
    "    \"\"\"\n",
    "    n_nodes = G.number_of_nodes()\n",
    "    n_edges = G.number_of_edges()\n",
    "    degrees = [d for _, d in G.degree()]\n",
    "\n",
    "    self_loops = nx.number_of_selfloops(G)\n",
    "    multi_edges = sum(1 for edge in G.edges() if G.number_of_edges(edge[0], edge[1]) > 1)\n",
    "\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    g_largest_cc = G.subgraph(largest_cc)\n",
    "\n",
    "    return {\n",
    "        'nodes': n_nodes,\n",
    "        'edges': n_edges,\n",
    "        'self_loops': self_loops,\n",
    "        'multi_edges': multi_edges,\n",
    "        'degree_min': np.min(degrees),\n",
    "        'degree_max': np.max(degrees),\n",
    "        'degree_avg': np.mean(degrees),\n",
    "        'clustering': nx.average_clustering(G),\n",
    "        'assortativity': nx.degree_assortativity_coefficient(G),\n",
    "        'avg_path_length': nx.average_shortest_path_length(g_largest_cc),\n",
    "        'diameter': nx.diameter(g_largest_cc),\n",
    "    }"
   ],
   "id": "6003e0600030a4f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `calculate_centralities` function computes key centrality measures for the nodes in a given network.",
   "id": "3db151341e680ba2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:10.971996Z",
     "start_time": "2025-03-23T20:43:10.969086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_centralities(G):\n",
    "    \"\"\"\n",
    "    Compute node centrality measures for a single network.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): The input graph.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - net_name: The name of the network.\n",
    "            - dict: A dictionary with centrality measures:\n",
    "                - 'betweenness': Betweenness centrality for each node.\n",
    "                - 'degree': Degree centrality for each node.\n",
    "                - 'eigenvector': Eigenvector centrality for each node.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'betweenness': nx.betweenness_centrality(G),\n",
    "        'degree': dict(G.degree()),\n",
    "        'eigenvector': nx.eigenvector_centrality(G)\n",
    "    }"
   ],
   "id": "7d40ddbfa1484656",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The function `get_top_central_nodes` extracts the top N most central nodes for each centrality metric from a given dictionary of centrality measures.",
   "id": "600bc7c1abaec87d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:10.975442Z",
     "start_time": "2025-03-23T20:43:10.973241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_central_nodes(centrality_dict, top_n=5):\n",
    "    \"\"\"\n",
    "    Retrieve the top N most central nodes for each centrality metric.\n",
    "\n",
    "    Parameters:\n",
    "        centrality_dict (dict): A dictionary containing centrality measures.\n",
    "        top_n (int): Number of top nodes to retrieve (default is 5).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the top N nodes for each metric.\n",
    "    \"\"\"\n",
    "    top_nodes = {}\n",
    "    for metric, values in centrality_dict.items():\n",
    "        sorted_nodes = sorted(values.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_nodes[metric] = [node for node, _ in sorted_nodes[:top_n]]\n",
    "    return top_nodes"
   ],
   "id": "c4b7358feeca0c54",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The function `plot_degree_distribution` visualizes the degree distribution of a network in both linear and logarithmic scales.",
   "id": "231d1497a86917c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:10.981034Z",
     "start_time": "2025-03-23T20:43:10.977645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_degree_distribution(degree_sequence, net_name):\n",
    "    \"\"\"\n",
    "    Plot degree distribution in both linear and logarithmic scales.\n",
    "\n",
    "    Parameters:\n",
    "        degree_sequence (list): List of node degrees\n",
    "        net_name (str): Network name for title and filename\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    degree_counts = Counter(degree_sequence)\n",
    "    min_degree = min(degree_sequence)\n",
    "    max_degree = max(degree_sequence)\n",
    "\n",
    "    degree = list(range(min_degree, max_degree + 1))\n",
    "    degree_count = [degree_counts.get(x, 0) for x in degree]\n",
    "\n",
    "    ax[0].scatter(degree, degree_count, label='data')\n",
    "    ax[0].set_xlabel('$k$', fontsize=15)\n",
    "    ax[0].set_ylabel('$P(k)$', fontsize=15)\n",
    "    ax[0].tick_params(which='major', axis='both', labelsize=15)\n",
    "    ax[0].set_title('Linear scale', fontsize=15)\n",
    "\n",
    "    ax[1].scatter(degree, degree_count, label='data')\n",
    "    ax[1].set_xlabel('$k$', fontsize=15)\n",
    "    ax[1].set_ylabel('$P(k)$', fontsize=15)\n",
    "    ax[1].set_yscale('log')\n",
    "    ax[1].set_xscale('log')\n",
    "    ax[1].tick_params(which='major', axis='both', labelsize=15)\n",
    "    ax[1].set_title('Logarithmic scale', fontsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.savefig(f'report/{net_name}_degree_distribution.png', bbox_inches='tight')"
   ],
   "id": "839e2480ec703ccd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:11.007738Z",
     "start_time": "2025-03-23T20:43:11.005490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_net(G, pos_dict, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw(G, pos=pos_dict, node_size=100, node_color='blue', edge_color='gray', alpha=0.7)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ],
   "id": "e4f9d77ea4efd27d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 1. Part 1\n",
    "Let's start by loading the networks from the files."
   ],
   "id": "f06c5d31aafa6ebb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:13.016676Z",
     "start_time": "2025-03-23T20:43:11.013668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NETWORK_NAMES = ['net1', 'net2', 'net3', 'net4']\n",
    "\n",
    "networks = {}\n",
    "for net_name in NETWORK_NAMES:\n",
    "    networks[net_name] = load_network(net_name)\n"
   ],
   "id": "1476f33b94e3591c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's calculate the descriptors and the centralities for each network.",
   "id": "b218358952c513f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:56.227073Z",
     "start_time": "2025-03-23T20:43:13.017773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tqdm_joblib(total=len(networks), desc=\"Analyzing networks\"):\n",
    "    descriptors = Parallel(n_jobs=-1)(delayed(calculate_network_descriptors)(G) for G in networks.values())"
   ],
   "id": "b14d1aece6bcc3cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyzing networks:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0685369a1fd423da4bbb7f1537abb85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm_joblib(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(networks), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnalyzing networks\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     descriptors \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcalculate_network_descriptors\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mG\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnetworks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cn/lib/python3.8/site-packages/joblib/parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cn/lib/python3.8/site-packages/joblib/parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cn/lib/python3.8/site-packages/joblib/parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[1;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[1;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[1;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T20:43:56.228858Z",
     "start_time": "2025-03-23T20:43:56.228718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tqdm_joblib(total=len(networks), desc=\"Calculating centralities\"):\n",
    "    centralities = Parallel(n_jobs=-1)(delayed(calculate_centralities)(G) for G in networks.values())"
   ],
   "id": "15219ff571e2af2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's calculate the top 5 nodes with the highest centrality based on the various metrics for each network and save the results in dataframes",
   "id": "2df019299deea0bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_nodes_per_network = {}\n",
    "for net_name, centrality_dict in zip(networks.keys(), centralities):\n",
    "    top_nodes_per_network[net_name] = get_top_central_nodes(centrality_dict, 5)\n",
    "\n",
    "df_centralities = {}\n",
    "for network_name in networks.keys():\n",
    "    df_centralities[network_name] = pd.DataFrame(top_nodes_per_network[network_name], index=[\"1\",\"2\",\"3\",\"4\",\"5\"]).T\n",
    "\n",
    "    #file_name = f\"{network_name}_centralities.md\"\n",
    "    #file_path = os.path.join(\"report\", file_name)\n",
    "\n",
    "    #with open(file_path, 'w') as file:\n",
    "    #    file.write(df_centralities[network_name].to_markdown())\n"
   ],
   "id": "579db73161ac4089",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's save the descriptors results in a dataframe",
   "id": "1f4d8e22762873b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_descriptors = pd.DataFrame(descriptors, index=[\"net1\",\"net2\",\"net3\",\"net4\"])\n",
    "\n",
    "file_name = f\"networks_descriptors.md\"  # Usa il nome della rete come nome del file\n",
    "file_path = os.path.join(\"report\", file_name)\n",
    "\n",
    "#with open(file_path, 'w') as file:\n",
    "#    file.write(df_descriptors.to_markdown())\n"
   ],
   "id": "f39004f29f2c27a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To systematically identify the generative mechanism behind each network, we begin by examining the key macroscopic properties, microscopic node centrality patterns, and degree distribution of each network.",
   "id": "8c28e66170af7afb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This multi-faceted analysis serves to identify the network's fundamental organizational principles and ultimately determine which generative model (ER, WS, BA, or Configuration Model) best explains its structure.",
   "id": "4848512020a9a346"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 Network 1 Analysis",
   "id": "dbf533ca2f3c6d05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_descriptors.iloc[[0]]",
   "id": "5b28b80b49630d41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_centralities['net1']",
   "id": "76627dc44ed17403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net1_centralities = centralities[0]\n",
    "degree_sequence_net1 = list(net1_centralities['degree'].values())\n",
    "plot_degree_distribution(degree_sequence_net1,'net1')"
   ],
   "id": "eb1dfed774c7959",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From the analysis of the degree distribution and the clustering coefficient of the network, it is possible to assert with high probability that the network was generated according to the Watts-Strogatz model.\n",
    "\n",
    "Networks constructed following this model exhibit the following characteristics:\n",
    "- A degree distribution similar to a Poisson distribution.\n",
    "- A high clustering coefficient ($CC \\geq 0.1$), which is typical of networks that exhibit the small-world property.\n"
   ],
   "id": "b637492ae60fbb37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 Network 2 analysis",
   "id": "81e4ee77a4084b6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_descriptors.iloc[[1]]",
   "id": "c218a49a8f4498ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_centralities['net2']",
   "id": "9ad162992504969c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net2_centralities = centralities[1]\n",
    "degree_sequence_net2 = list(net2_centralities['degree'].values())\n",
    "plot_degree_distribution(degree_sequence_net2,'net2')"
   ],
   "id": "2710a39dd5167ad5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "The degree distribution analysis suggests that this network was generated using the Erdős-Rényi (ER) random graph model. Indeed, the observed degree distribution exhibits a **Poisson-like form**, characterized by a symmetric distribution around the average degree $ ( \\langle k \\rangle )$.\n",
    "\n",
    "To verify the validity of this assumption, we can consider the following key properties of networks generated under this model:\n",
    "\n",
    "- The average degree is given by\n",
    "\n",
    "  $$ \\langle k \\rangle \\sim p (N - 1) $$\n",
    "\n",
    "- The clustering coefficient is\n",
    "\n",
    "  $$ CC = p $$\n",
    "\n",
    "Therefore, to determine with high probability whether this network was generated following the ER model, it is sufficient to compute $( CC(N - 1) )$ and compare it with the average degree.\n"
   ],
   "id": "d759c8010ac16d29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "avg_degree = 9.9492\n",
    "N = 5000\n",
    "CC = 0.0020994830917276737\n",
    "\n",
    "print(CC * (N-1))\n"
   ],
   "id": "a602a1510811b789",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since $ 9.94 \\sim 10.4 $, we can conclude that, with high probability, the hypothesis is correct and the network was generated according to the ER model.",
   "id": "e29432aa33ade87a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 Network 3 Analysis",
   "id": "d145882d3db7faae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_descriptors.iloc[[2]]",
   "id": "59c6c757b86ad62a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_centralities['net3']\n",
   "id": "85ef6582e26cc445",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net3_centralities = centralities[2]\n",
    "degree_sequence_net3= list(net3_centralities['degree'].values())\n",
    "plot_degree_distribution(degree_sequence_net3,'net3')"
   ],
   "id": "649ca90f8cb149f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It is evident from the structural characteristics of the network that it was generated according to the Configuration Model (CM).\n",
    "\n",
    "In particular, the network exhibits 16 self-loops, which are a direct consequence of the nature of networks following this model.\n"
   ],
   "id": "919cc6f05a11a790"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.4 Network 4 Analysis",
   "id": "9cef85fce23ba789"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_descriptors.iloc[[3]]",
   "id": "f4d2ddfc183934c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_centralities['net4']",
   "id": "3474c753d05938ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net4_centralities = centralities[3]\n",
    "degree_sequence_net4= list(net4_centralities['degree'].values())\n",
    "plot_degree_distribution(degree_sequence_net4,'net4')"
   ],
   "id": "5d450eeb783c3a8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There are two pieces of evidence supporting the assertion that, with high probability, network number 4 was generated according to the Barabási-Albert model:\n",
    "\n",
    "1. The network exhibits a power-law distribution, which can be observed by analyzing the degree distribution on a log-log scale.\n",
    "2. Additionally, examining the nodes with the highest degree, it is evident that they all have low indices. This is a consequence of the algorithm used, which favors the attachment of new edges to the earliest nodes introduced in the network.\n"
   ],
   "id": "29a4d0c897069ce3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.5 Conclusions",
   "id": "9ac3fa58c9757e7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In conclusion, based on the observations made, the networks can be classified as follows:\n",
    "\n",
    "| Network  | Model                |\n",
    "|----------|----------------------|\n",
    "| Network 1 | Watts-Strogatz       |\n",
    "| Network 2 | Erdős-Rényi          |\n",
    "| Network 3 | Configuration Model  |\n",
    "| Network 4 | Barabási-Albert      |\n"
   ],
   "id": "bbd2a780d3696b7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Part 2",
   "id": "bf32ce7558d339c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Network Visualization",
   "id": "a943bfce0e7aab36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's load and visualize the network 5",
   "id": "c35b5d0276f7f5b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "G = load_network('net5')\n",
    "pos= np.loadtxt('data/positions_net5.txt', skiprows=1)\n",
    "pos_dict = {int(row[0]): (row[1], row[2]) for row in pos}\n",
    "\n",
    "visualize_net(G , pos_dict, \"Network 5 Visualization\")\n"
   ],
   "id": "381f49985436ea5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Observation and hypothesis",
   "id": "5ab030dd429be216"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We know a priori that all nodes were randomly generated in space. The model, therefore, only determines how and in what order edges are added between them.\n",
    "\n",
    "\n",
    "Observation 1: By analyzing the network, it is immediately evident that nodes in close proximity are always connected by an edge, whereas edges between distant nodes are much rarer.\n",
    "\n",
    "\n",
    "Observation 2: Furthermore, in the case of distant nodes that are connected by an edge, it appears that all other node pairs with a smaller distance also have an edge.\n",
    "\n",
    "Based on these observations, the hypothesis is that the criterion for adding new edges is based on the physical space in which the nodes are located. Thus, the nodes' coordinates are likely attributes of the nodes, as they define a notion of distance between them.\n",
    "\n",
    "Additionally, Observation 2 suggests that edges are inserted in a specific order. More precisely, the hypothesis is that, given a predetermined number of edges, at each iteration of the model’s algorithm, an edge is added between the pair of nodes with the smallest distance, provided they are not already connected.\n"
   ],
   "id": "6a4cf3a30fba4383"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 Algorithm Construction for the Model",
   "id": "bcf586735cfbcf15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Our proposed algorithm for the possible model that could have generated this network is as follows:\n",
    "\n",
    "1. Compute all possible pairs of nodes in the network.\n",
    "2. For each pair of nodes, calculate the Euclidean distance between them.\n",
    "3. Sort the list of node pairs in ascending order based on their distance.\n",
    "4. Iteratively add an edge to the pair of nodes with the smallest distance until the predefined number of edges is reached.\n"
   ],
   "id": "52433a164262ade3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def euclidean_distance_model(G,pos_dict,n_edges):\n",
    "    nodes = list(pos_dict.keys())\n",
    "    pairs = combinations(nodes, 2)\n",
    "    distance_list = []\n",
    "    for u, v in pairs:\n",
    "        x1 , y1 = pos_dict[u]\n",
    "        x2, y2 = pos_dict[v]\n",
    "        distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        distance_list.append((distance, u, v))\n",
    "\n",
    "    distance_list.sort(key=lambda x: x[0])\n",
    "\n",
    "    ordered_pairs = [(u, v) for (d, u, v) in distance_list]\n",
    "\n",
    "    for i in range(n_edges):\n",
    "        G.add_edge(ordered_pairs[i][0], ordered_pairs[i][1])\n",
    "    return G"
   ],
   "id": "fa3e63e3bee79d59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.4 Algorithm proposal testing",
   "id": "478ba67bd9225e1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lets testing the algorithm. Firstly we need to remove all the edges from the initial network in order to start from the basic configuration",
   "id": "58544b36b62a23b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "G_testing = G.copy()\n",
    "G_testing.clear_edges()\n",
    "\n",
    "visualize_net(G_testing, pos_dict, \"Network 5 Visualization without edges\")"
   ],
   "id": "18be570212183e7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now test the algorithm. Let's see how many nodes there are in the initial network and then we can test the proposal model.",
   "id": "4e6c33457359752b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_edge = G.number_of_edges()\n",
    "\n",
    "G_testing = euclidean_distance_model(G_testing,pos_dict,n_edge)\n",
    "\n",
    "visualize_net(G_testing, pos_dict, \"Network 5 created according to the proposed model\")"
   ],
   "id": "4b937cb8841f69d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's see if the edges are the same in both the networks, the first one and the new created",
   "id": "6342074876b0e7c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(set(G.edges()) == set(G_testing.edges()))",
   "id": "bf52a24a7c7ded51",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
